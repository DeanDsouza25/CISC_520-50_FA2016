'''
Created on Nov 29, 2016

@author: demon
'''
# Loading necessary Libraries
from __future__ import division
import nltk
from nltk.text import Text
from ProjectTokenizer import pToken
from ProjectTagger import pTagger

# Loading all text data
txtFile=open('C:/Users/demon/OneDrive/Documents/GitHub/CISC_520-50_FA2016/Project/data/AllText.txt','r')
tempTxt = txtFile.read()
txtFile.close()

# Tokenizing the text
pTok=pToken(tempTxt)

# Basic statistics of the text
print("Number of Words : "+str(len(pTok)))
print("Number of Unique Words : "+str(len(set(pTok))))
print("Lexical Diversity : "+str(len(pTok)/len(set(pTok))))

# Converting to nltk.text.Text form to easily create Frequency Distribution 
nText = Text(pTok)
fdistv = nltk.FreqDist(nText)
vocab = fdistv.keys()

# List of top most tokens
print(vocab[:50])

# Cummulative Frequency Plot of the top most tokens
fdistv.plot(50,cumulative=True)

# Collocations (a.k.a. Words occuring together with a frequency considered greater than chance)
print(nText.collocations())

# Tagging the tokens with Part-of-Speech tag
taggedTok = pTagger(vocab)
tags = [t for (w,t) in taggedTok]

# Frequency Distribution of tags
fdisttag=nltk.FreqDist(tags)
fdisttag.tabulate()

# Frequency Distribution Plot of tags
fdisttag.plot()
